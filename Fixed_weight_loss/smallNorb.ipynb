{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader taken from https://github.com/mavanb/vision/blob/448fac0f38cab35a387666d553b9d5e4eec4c5e6/torchvision/datasets/utils.py\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import errno\n",
    "import struct\n",
    "from skimage import io\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "\n",
    "\n",
    "class SmallNORB(data.Dataset):\n",
    "    \"\"\"`MNIST <https://cs.nyu.edu/~ylclab/data/norb-v1.0-small//>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where processed folder and\n",
    "            and  raw folder exist.\n",
    "        train (bool, optional): If True, creates dataset from the training files,\n",
    "            otherwise from the test files.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If the dataset is already processed, it is not processed\n",
    "            and downloaded again. If dataset is only already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        info_transform (callable, optional): A function/transform that takes in the\n",
    "            info and transforms it.\n",
    "        mode (string, optional): Denotes how the images in the data files are returned. Possible values:\n",
    "            - all (default): both left and right are included separately.\n",
    "            - stereo: left and right images are included as corresponding pairs.\n",
    "            - left: only the left images are included.\n",
    "            - right: only the right images are included.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_root = \"https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/\"\n",
    "    data_files = {\n",
    "        'train': {\n",
    "            'dat': {\n",
    "                \"name\": 'smallnorb-5x46789x9x18x6x2x96x96-training-dat.mat',\n",
    "                \"md5_gz\": \"66054832f9accfe74a0f4c36a75bc0a2\",\n",
    "                \"md5\": \"8138a0902307b32dfa0025a36dfa45ec\"\n",
    "            },\n",
    "            'info': {\n",
    "                \"name\": 'smallnorb-5x46789x9x18x6x2x96x96-training-info.mat',\n",
    "                \"md5_gz\": \"51dee1210a742582ff607dfd94e332e3\",\n",
    "                \"md5\": \"19faee774120001fc7e17980d6960451\"\n",
    "            },\n",
    "            'cat': {\n",
    "                \"name\": 'smallnorb-5x46789x9x18x6x2x96x96-training-cat.mat',\n",
    "                \"md5_gz\": \"23c8b86101fbf0904a000b43d3ed2fd9\",\n",
    "                \"md5\": \"fd5120d3f770ad57ebe620eb61a0b633\"\n",
    "            },\n",
    "        },\n",
    "        'test': {\n",
    "            'dat': {\n",
    "                \"name\": 'smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat',\n",
    "                \"md5_gz\": \"e4ad715691ed5a3a5f138751a4ceb071\",\n",
    "                \"md5\": \"e9920b7f7b2869a8f1a12e945b2c166c\"\n",
    "            },\n",
    "            'info': {\n",
    "                \"name\": 'smallnorb-5x01235x9x18x6x2x96x96-testing-info.mat',\n",
    "                \"md5_gz\": \"a9454f3864d7fd4bb3ea7fc3eb84924e\",\n",
    "                \"md5\": \"7c5b871cc69dcadec1bf6a18141f5edc\"\n",
    "            },\n",
    "            'cat': {\n",
    "                \"name\": 'smallnorb-5x01235x9x18x6x2x96x96-testing-cat.mat',\n",
    "                \"md5_gz\": \"5aa791cd7e6016cf957ce9bdb93b8603\",\n",
    "                \"md5\": \"fd5120d3f770ad57ebe620eb61a0b633\"\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    train_image_file = 'train_img'\n",
    "    train_label_file = 'train_label'\n",
    "    train_info_file = 'train_info'\n",
    "    test_image_file = 'test_img'\n",
    "    test_label_file = 'test_label'\n",
    "    test_info_file = 'test_info'\n",
    "    extension = '.pt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, info_transform=None, download=False,\n",
    "                 mode=\"stereo\"):\n",
    "\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.info_transform = info_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.mode = mode\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # load test or train set\n",
    "        image_file = self.train_image_file if self.train else self.test_image_file\n",
    "        label_file = self.train_label_file if self.train else self.test_label_file\n",
    "        info_file = self.train_info_file if self.train else self.test_info_file\n",
    "\n",
    "        # load labels\n",
    "        self.labels = self._load(label_file)\n",
    "\n",
    "        # load info files\n",
    "        self.infos = self._load(info_file)\n",
    "\n",
    "        # load right set\n",
    "        if self.mode == \"left\":\n",
    "            self.data = self._load(\"{}_left\".format(image_file))\n",
    "\n",
    "        # load left set\n",
    "        elif self.mode == \"right\":\n",
    "            self.data = self._load(\"{}_right\".format(image_file))\n",
    "\n",
    "        elif self.mode == \"all\" or self.mode == \"stereo\":\n",
    "            left_data = self._load(\"{}_left\".format(image_file))\n",
    "            right_data = self._load(\"{}_right\".format(image_file))\n",
    "\n",
    "            # load stereo\n",
    "            if self.mode == \"stereo\":\n",
    "                self.data = torch.stack((left_data, right_data), dim=1)\n",
    "\n",
    "            # load all\n",
    "            else:\n",
    "                self.data = torch.cat((left_data, right_data), dim=0)\n",
    "        print(self.data.size())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            mode ``all'', ``left'', ``right'':\n",
    "                tuple: (image, target, info)\n",
    "            mode ``stereo'':\n",
    "                tuple: (image left, image right, target, info)\n",
    "        \"\"\"\n",
    "        target = self.labels[index % 24300] if self.mode is \"all\" else self.labels[index]\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        info = self.infos[index % 24300] if self.mode is \"all\" else self.infos[index]\n",
    "        if self.info_transform is not None:\n",
    "            info = self.info_transform(info)\n",
    "\n",
    "        if self.mode == \"stereo\":\n",
    "            img_left = self._transform(self.data[index, 0])\n",
    "            img_right = self._transform(self.data[index, 1])\n",
    "            img = torch.cat((img_left,img_right),dim=0)\n",
    "\n",
    "            return img,target #img_left, img_right, target, info\n",
    "\n",
    "        img = self._transform(self.data[index])\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _transform(self, img):\n",
    "        # doing this so that it is consistent with all other data sets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy())#, mode='L')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "    def _load(self, file_name):\n",
    "        return torch.load(os.path.join(self.root, self.processed_folder, file_name + self.extension))\n",
    "\n",
    "    def _save(self, file, file_name):\n",
    "        with open(os.path.join(self.root, self.processed_folder, file_name + self.extension), 'wb') as f:\n",
    "            torch.save(file, f)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        \"\"\" Check if processed files exists.\"\"\"\n",
    "        files = (\n",
    "            \"{}_left\".format(self.train_image_file),\n",
    "            \"{}_right\".format(self.train_image_file),\n",
    "            \"{}_left\".format(self.test_image_file),\n",
    "            \"{}_right\".format(self.test_image_file),\n",
    "            self.test_label_file,\n",
    "            self.train_label_file\n",
    "        )\n",
    "        fpaths = [os.path.exists(os.path.join(self.root, self.processed_folder, f + self.extension)) for f in files]\n",
    "        return False not in fpaths\n",
    "\n",
    "    def _flat_data_files(self):\n",
    "        return [j for i in self.data_files.values() for j in list(i.values())]\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        \"\"\"Check if unpacked files have correct md5 sum.\"\"\"\n",
    "        root = self.root\n",
    "        for file_dict in self._flat_data_files():\n",
    "            filename = file_dict[\"name\"]\n",
    "            md5 = file_dict[\"md5\"]\n",
    "            fpath = os.path.join(root, self.raw_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the SmallNORB data if it doesn't exist in processed_folder already.\"\"\"\n",
    "        import gzip\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        # check if already extracted and verified\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "        else:\n",
    "            # download and extract\n",
    "            for file_dict in self._flat_data_files():\n",
    "                url = self.dataset_root + file_dict[\"name\"] + '.gz'\n",
    "                filename = file_dict[\"name\"]\n",
    "                gz_filename = filename + '.gz'\n",
    "                md5 = file_dict[\"md5_gz\"]\n",
    "                fpath = os.path.join(self.root, self.raw_folder, filename)\n",
    "                gz_fpath = fpath + '.gz'\n",
    "\n",
    "                # download if compressed file not exists and verified\n",
    "                download_url(url, os.path.join(self.root, self.raw_folder), gz_filename, md5)\n",
    "\n",
    "                print('# Extracting data {}\\n'.format(filename))\n",
    "\n",
    "                with open(fpath, 'wb') as out_f, \\\n",
    "                        gzip.GzipFile(gz_fpath) as zip_f:\n",
    "                    out_f.write(zip_f.read())\n",
    "\n",
    "                os.unlink(gz_fpath)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        # create processed folder\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # read train files\n",
    "        left_train_img, right_train_img = self._read_image_file(self.data_files[\"train\"][\"dat\"][\"name\"])\n",
    "        train_info = self._read_info_file(self.data_files[\"train\"][\"info\"][\"name\"])\n",
    "        train_label = self._read_label_file(self.data_files[\"train\"][\"cat\"][\"name\"])\n",
    "\n",
    "        # read test files\n",
    "        left_test_img, right_test_img = self._read_image_file(self.data_files[\"test\"][\"dat\"][\"name\"])\n",
    "        test_info = self._read_info_file(self.data_files[\"test\"][\"info\"][\"name\"])\n",
    "        test_label = self._read_label_file(self.data_files[\"test\"][\"cat\"][\"name\"])\n",
    "\n",
    "        # save training files\n",
    "        self._save(left_train_img, \"{}_left\".format(self.train_image_file))\n",
    "        self._save(right_train_img, \"{}_right\".format(self.train_image_file))\n",
    "        self._save(train_label, self.train_label_file)\n",
    "        self._save(train_info, self.train_info_file)\n",
    "\n",
    "        # save test files\n",
    "        self._save(left_test_img, \"{}_left\".format(self.test_image_file))\n",
    "        self._save(right_test_img, \"{}_right\".format(self.test_image_file))\n",
    "        self._save(test_label, self.test_label_file)\n",
    "        self._save(test_info, self.test_info_file)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_header(file_pointer):\n",
    "        # Read magic number and ignore\n",
    "        struct.unpack('<BBBB', file_pointer.read(4))  # '<' is little endian)\n",
    "\n",
    "        # Read dimensions\n",
    "        dimensions = []\n",
    "        num_dims, = struct.unpack('<i', file_pointer.read(4))  # '<' is little endian)\n",
    "        for _ in range(num_dims):\n",
    "            dimensions.extend(struct.unpack('<i', file_pointer.read(4)))\n",
    "\n",
    "        return dimensions\n",
    "\n",
    "    def _read_image_file(self, file_name):\n",
    "        fpath = os.path.join(self.root, self.raw_folder, file_name)\n",
    "        with open(fpath, mode='rb') as f:\n",
    "            dimensions = self._parse_header(f)\n",
    "            assert dimensions == [24300, 2, 96, 96]\n",
    "            num_samples, _, height, width = dimensions\n",
    "\n",
    "            left_samples = np.zeros(shape=(num_samples, height, width), dtype=np.uint8)\n",
    "            right_samples = np.zeros(shape=(num_samples, height, width), dtype=np.uint8)\n",
    "\n",
    "            for i in range(num_samples):\n",
    "\n",
    "                # left and right images stored in pairs, left first\n",
    "                left_samples[i, :, :] = self._read_image(f, height, width)\n",
    "                right_samples[i, :, :] = self._read_image(f, height, width)\n",
    "        \n",
    "        return torch.ByteTensor(left_samples), torch.ByteTensor(right_samples)\n",
    "\n",
    "    @staticmethod\n",
    "    def _read_image(file_pointer, height, width):\n",
    "        \"\"\"Read raw image data and restore shape as appropriate. \"\"\"\n",
    "        image = struct.unpack('<' + height * width * 'B', file_pointer.read(height * width))\n",
    "        image = np.uint8(np.reshape(image, newshape=(height, width)))\n",
    "        return image\n",
    "\n",
    "    def _read_label_file(self, file_name):\n",
    "        fpath = os.path.join(self.root, self.raw_folder, file_name)\n",
    "        with open(fpath, mode='rb') as f:\n",
    "            dimensions = self._parse_header(f)\n",
    "            assert dimensions == [24300]\n",
    "            num_samples = dimensions[0]\n",
    "\n",
    "            struct.unpack('<BBBB', f.read(4))  # ignore this integer\n",
    "            struct.unpack('<BBBB', f.read(4))  # ignore this integer\n",
    "\n",
    "            labels = np.zeros(shape=num_samples, dtype=np.int32)\n",
    "            for i in range(num_samples):\n",
    "                category, = struct.unpack('<i', f.read(4))\n",
    "                labels[i] = category\n",
    "            return torch.LongTensor(labels)\n",
    "\n",
    "    def _read_info_file(self, file_name):\n",
    "        fpath = os.path.join(self.root, self.raw_folder, file_name)\n",
    "        with open(fpath, mode='rb') as f:\n",
    "\n",
    "            dimensions = self._parse_header(f)\n",
    "            assert dimensions == [24300, 4]\n",
    "            num_samples, num_info = dimensions\n",
    "\n",
    "            struct.unpack('<BBBB', f.read(4))  # ignore this integer\n",
    "\n",
    "            infos = np.zeros(shape=(num_samples, num_info), dtype=np.int32)\n",
    "\n",
    "            for r in range(num_samples):\n",
    "                for c in range(num_info):\n",
    "                    info, = struct.unpack('<i', f.read(4))\n",
    "                    infos[r, c] = info\n",
    "\n",
    "        return torch.LongTensor(infos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
